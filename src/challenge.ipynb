{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaci√≥n de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gcp import q1_bigquery\n",
    "from q1_time import q1_time, q1_time_pandas\n",
    "from q1_memory import q1_memory\n",
    "from q2_time import q2_time, q2_time_pandas\n",
    "from q2_memory import q2_memory\n",
    "from q3_time import q3_time, q3_time_pandas\n",
    "from q3_memory import q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoque general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grandes rasgos por cada pregunta se realiza lo siguente:\n",
    " - Optimizaci√≥n de tiempo de ejecuci√≥n cargando los datos en un DataFrame\n",
    "     - Se usa la librer√≠a Pandas.\n",
    "     - Se usa librer√≠a Polars, dada su capacidad de procesar grandes vol√∫menes de datos de forma r√°pida y eficiente.\n",
    " - Optimizaci√≥n de uso de memor√≠a leyendo el JSON l√≠nea a l√≠nea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La hip√≥tesis es que para optimizar la velocidad resulta mejor cargar los datos a un Dataframe, ya sea de Pandas o Polars, debido a que est√°n optimizados para trabajar de manera eficiente. De esta forma la manipulaci√≥n de los datos y la aplicaci√≥n de operaciones deber√≠a ser m√°s r√°pida.\n",
    "\n",
    "Por otra parte, resulta evidente que para optimizar el uso de memoria cargar todos los datos a un Dataframe no es el camino correcto. Resulta mucho m√°s conveniente leer cada tweet, iterando el JSON linea a l√≠nea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suposiciones\n",
    "- Se presupone que se tiene el archivo JSON en la misma carpeta que este notebook.\n",
    "- Se supone que el archivo ya est√° extraido del zip.\n",
    "- Para ejecutar la funci√≥n basada en BigQuery se asume que ya se tiene un proyecto creado, con una cuenta de servicio con permisos de administrador de BigQuery y de objetos de storage (y disponemos de la key de la cuenta en formato JSON).\n",
    "- Se asume que se tiene un dataset en BigQuery con una tabla con los datos del JSON cargados.\n",
    "- Se asume que tenemos las variables de entorno *PROJECT_ID*, *KEYFILE_PATH*, *DATASET_ID* y *TABLE_NAME* en el entorno virtual para usar BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En el notebook **setup_gcp.ipynb** se explica m√°s en detalle el preparamiento para usar BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener las top 10 fechas con m√°s tweets y mencionar el usuario con m√°s publicaciones en cada uno de esos d√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Optimizaci√≥n de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 Enfoque usando BigQuery de Google Cloud Platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea objeto Client de BigQuery a partir del *project_id* y el path de la *keyfile*.\n",
    "- Se arma la query SQL, reemplazando el *project_id*, *dataset_id* y *table_name* seg√∫n los argumentos entregados a la funci√≥n.\n",
    "- Se crea un BigQuery Job para ejecutar la query.\n",
    "- Se entrega resultado como lista de tuplas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "keyfile_path = os.getenv(\"KEYFILE_PATH\")\n",
    "dataset_id = os.getenv(\"DATASET_ID\")\n",
    "table_name = os.getenv(\"TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "print(q1_bigquery(keyfile_path, project_id, dataset_id, table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.62 s ¬± 117 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_bigquery(keyfile_path, project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 157.85 MiB, increment: 0.14 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_bigquery(keyfile_path, project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Enfoque usando librer√≠a Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea LazyFrame para leer el JSON.\n",
    "- Se seleccionan de columnas a usar, tomando *date* y *username* (desde dentro de *user*).\n",
    "- Se agrega columna *date_count* con conteo de tweets por d√≠a (usando l√≥gica *over* similar a funciones de venta en SQL).\n",
    "- Se agrega columna *user_count* con conteo tweets por combinacion de d√≠a y username (usando l√≥gica *over*).\n",
    "- Se ordena seg√∫n *user_count*, se agrupa seg√∫n *date* y se extrae el primer username por cada partici√≥n, junto con *date_count* asociada.\n",
    "- Se ordena el resultado (una fila por d√≠a) por *date_count* descendiente y se extraen los primeros 10.\n",
    "- Se materializa el LazyFrame a DataFrame.\n",
    "- Se entrega resultado como lista de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "print(q1_time(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.91 s ¬± 120 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1675.81 MiB, increment: 1524.47 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Enfoque usando librer√≠a Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se cargan de datos del JSON en un Dataframe.\n",
    "- Se seleccionan de columnas a usar, tomando date y username (desde dentro de user).\n",
    "- Se obtienen indices de los 10 d√≠as con m√°s tweets y se filtran del dataframe.\n",
    "- Se agrega columna *count* con conteo tweets por combinacion de d√≠a y username (usando *group_by*).\n",
    "- Se obtienen los √≠ndices de usernames con m√°s tweets por d√≠a haciendo *group_by* por d√≠a y extrayendo el √≠ndice de la fila con mayor *count* de cada partici√≥n.\n",
    "- Se extraen los usernames del Dataframe seg√∫n √≠ndices encontrados, se elimina columna con conteo y se entrega salida como lista de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria')]\n"
     ]
    }
   ],
   "source": [
    "print(q1_time_pandas(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.65 s ¬± 445 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3247.39 MiB, increment: 2039.49 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Optimizaci√≥n de uso de memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque leyendo l√≠nea a l√≠nea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se lee JSON entero l√≠nea por l√≠nea, creando diccionario con cada d√≠a distinto como *key* y el conteo de tweets del d√≠a como *value*.\n",
    "- Se ordena diccionario seg√∫n conteo y se extraen los 10 d√≠as m√°ximos.\n",
    "- Por cada uno de los 10 d√≠as m√°ximos:\n",
    "    - Se lee JSON en l√≠nea por l√≠nea, creando diccionario con cada username como *key* y el conteo de tweets del user como *value*.\n",
    "    - Se ordena diccionario y se extrae el username con m√°s publicaciones del d√≠a (se agrega como tupla a una lista de salida).\n",
    "- Se entrega lista resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cabe mencionar que se est√° leyendo el JSON l√≠nea por l√≠nea 11 veces, lo que obviamente es lento, pero se hace debido al enfoque en uso de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La idea es evitar crear un diccionario con dias como keys y diccionario de usernames como values, ya que esta variable ocupar√≠a gran cantidad de memor√≠a.\n",
    "> Se prefiere iterar d√≠a a d√≠a extrayendo el username m√°s mencionado, manteniendo en comparaci√≥n una variable de menor tama√±o que se sobreescribe en cada iteraci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "print(q1_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 25s ¬± 818 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 148.39 MiB, increment: 1.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 An√°lisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En cuanto al tiempo de ejecuci√≥n se puede ver que usar Polars es un 1.7 veces m√°s r√°pido que Pandas y 17 veces m√°s r√°pido que el enfoque en optimizaci√≥n de memoria. Es 0.53 veces m√°s lento que BigQuery.\n",
    "- En cuanto a uso de memoria, el enfoque leyendo l√≠nea a l√≠nea es 11 veces menor a usando Polars y 22 veces menor a usando Pandas. Ocupa aproximadamente la misma memoria que el enfoque usando BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los top 10 emojis m√°s usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la realizaci√≥n de esta pregunta se utiliza la librer√≠a *emojis*.   \n",
    "Se consider√≥ la posibilidad de encontrar los emojis usando expresiones regulares debido a su mayor velocidad, pero se termina usando librer√≠a emojis para tener mayor precisi√≥n en los resultados.\n",
    "\n",
    "> Se hace la suposici√≥n de que no se quieren agrupar emojis de la misma \"forma\" pero distinto color.\n",
    "> Por ejemplo, coraz√≥n rojo y verde o *praying hands* de distinto tono de piel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Optimizaci√≥n de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Enfoque usando librer√≠a Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea LazyFrame para leer el JSON.\n",
    "- Se seleccionan las columnas a usar, tomando *content* y aplicando una funci√≥n para mapear *content* a una lista de emojis contenidos.\n",
    "- Se filtran tweets sin emojis.\n",
    "- Se materializa el LazyFrame a DataFrame.\n",
    "- Se \"abren\" las filas creando una fila nueva por cada emoji en la lista.\n",
    "- Se crea dataframe con conteo por emojis, se ordena de manera descendente y se extraen los 10 m√°s usados.\n",
    "- Se entrega resultado como lista de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "print(q2_time(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 s ¬± 181 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1034.31 MiB, increment: 386.59 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q2_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Enfoque usando librer√≠a Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se cargan de datos del JSON en un Dataframe.\n",
    "- Se seleccionan las columnas a usar, tomando *content* y aplicando una funci√≥n para mapear *content* a una lista de emojis contenidos.\n",
    "- Se \"abren\" las filas creando una fila nueva por cada emoji en la lista.\n",
    "- Se crea dataframe con conteo por emojis, se ordena de manera descendente y se extraen los 10 m√°s usados.\n",
    "- Se entrega resultado como lista de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5049, 'üôè'), (3072, 'üòÇ'), (2972, 'üöú'), (2182, 'üåæ'), (2086, 'üáÆüá≥'), (1668, 'ü§£'), (1651, '‚úä'), (1382, '‚ù§Ô∏è'), (1317, 'üôèüèª'), (1040, 'üíö')]\n"
     ]
    }
   ],
   "source": [
    "print(q2_time_pandas(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.7 s ¬± 532 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3620.69 MiB, increment: 2596.27 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q2_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Optimizaci√≥n de uso de memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque leyendo l√≠nea a l√≠nea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea un contador *Counter()* para los emojis.\n",
    "- Se lee JSON entero l√≠nea por l√≠nea y por cada una:\n",
    "    - Se extrae campo *content* y se extrae lista de emojis con librer√≠a *emojis*.\n",
    "    - Por cada emoji en la lista se actualiza el contador de emojis.\n",
    "- Se encuentran los 10 emojis m√°s usados con m√©todo *most_common(10)* y se entregan como salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n"
     ]
    }
   ],
   "source": [
    "print(q2_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2 s ¬± 670 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 149.76 MiB, increment: 1.38 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 An√°lisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En cuanto al tiempo de ejecuci√≥n se puede ver que usar Polars es un 1.23 veces m√°s r√°pido que Pandas y 1.14 veces m√°s r√°pido que el enfoque en optimizaci√≥n de memoria.\n",
    "- En cuanto a uso de memoria, el enfoque leyendo l√≠nea a l√≠nea es 6.9 veces menor a usando Polars y 24 veces menor a usando Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la realizaci√≥n de esta pregunta se utiliza el campo *mentionedUsers* de los tweets.   \n",
    "Se consider√≥ la posibilidad de usar expresiones regulares haciendo uso del @, pero se prefir√≠o usar el campo de usuarios mencionados, ya que probablemente entrega resultados m√°s precisos (en teor√≠a pueden haber @ no usados para referenciar a otros users, como en correos).\n",
    "\n",
    "> Se hace la suposici√≥n de que por cada tweet se menciona m√°ximo una vez a cada *username* distinto (en teor√≠a se puede mencionar m√°s de una vez en un mismo tweet a alguien). Dado que es algo que no ocurre demasiado, probablemente no afecta los resultados finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Optimizaci√≥n de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Enfoque usando librer√≠a Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea LazyFrame para leer el JSON.\n",
    "- Se seleccionan las columnas a usar, tomando *mentionedUsers* y aplicando una funci√≥n para mapear *mentionedUsers* a una lista de *usernames* contenidos.\n",
    "- Se filtran tweets sin menciones a otros usurios.\n",
    "- Se materializa el LazyFrame a DataFrame.\n",
    "- Se \"abren\" las filas creando una fila nueva por cada *username* en la lista.\n",
    "- Se crea dataframe con conteo por *usernames*, se ordena de manera descendente y se extraen los 10 m√°s mencionados.\n",
    "- Se entrega resultado como lista de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "print(q3_time(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.91 s ¬± 320 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1398.32 MiB, increment: 461.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q3_time(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Enfoque usando librer√≠a Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se cargan de datos del JSON en un Dataframe.\n",
    "- Se seleccionan las columnas a usar, tomando *mentionedUsers* y aplicando una funci√≥n para mapear *mentionedUsers* a una lista de *usernames* contenidos.\n",
    "- Se \"abren\" las filas creando una fila nueva por cada *username* en la lista.\n",
    "- Se crea dataframe con conteo por *usernames*, se ordena de manera descendente y se extraen los 10 m√°s usados.\n",
    "- Se entrega resultado como lista de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2265, 'narendramodi'), (1840, 'Kisanektamorcha'), (1644, 'RakeshTikaitBKU'), (1427, 'PMOIndia'), (1146, 'RahulGandhi'), (1048, 'GretaThunberg'), (1019, 'RaviSinghKA'), (986, 'rihanna'), (962, 'UNHumanRights'), (926, 'meenaharris')]\n"
     ]
    }
   ],
   "source": [
    "print(q3_time_pandas(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.1 s ¬± 156 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3311.57 MiB, increment: 2658.90 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q3_time_pandas(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Optimizaci√≥n de uso de memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque leyendo l√≠nea a l√≠nea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se crea un contador *Counter()* para los *usernames* mencionados.\n",
    "- Se lee JSON entero l√≠nea por l√≠nea y por cada una:\n",
    "    - Se extrae campo *mentionedUsers* y se extrae lista de *usernames*.\n",
    "    - Por cada *username* en la lista se actualiza el contador de *usernames*.\n",
    "- Se encuentran los 10 *usernames* m√°s usados con m√©todo *most_common(10)* y se entregan como salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado de la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "print(q3_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7 s ¬± 117 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C√°lculo de uso de memor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 151.32 MiB, increment: 1.56 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 An√°lisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En cuanto al tiempo de ejecuci√≥n se puede ver que el enfoque en optimizaci√≥n de memoria es 1.5 veces m√°s r√°pido que Polars y 1.4 veces m√°s r√°pido que Pandas.\n",
    "- En cuanto a uso de memoria, el enfoque leyendo l√≠nea a l√≠nea es 9.2 veces menor a usando Polars y 22 veces menor a usando Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se concluye que Polars es mucho m√°s r√°pido para leer JSON separados por lineas gracias a su funcion scan_ndjson. El uso de LazyFrames realmente hace una diferencia comparado con la carga directa a un Dataframe de Pandas.\n",
    "\n",
    "- Se ve que el uso de memor√≠a usando Polars es significativamente menor al de Pandas.\n",
    "\n",
    "- Se evidencia que cargar datos con estructura anidada y de un tama√±o importante a un Dataframe no es una operaci√≥n r√°pida.\n",
    "\n",
    "- Resulta interesante que el enfoque para optimizar el uso de memoria, leyendo l√≠nea por linea resulta m√°s r√°pido en varios casos. Probablemente la raz√≥n es el tiempo de carga de los datos de Polars y sobre todo de Pandas.\n",
    "\n",
    "- El enfoque basado en BigQuery resulta mucho m√°s r√°pido que el resto, pero la comparaci√≥n es injusta, puesto que no se considera el tiempo de la carga de datos.\n",
    "\n",
    "- En cuanto a la optimizaci√≥n del uso de memoria se puede ver que leer l√≠nea por linea supera consistentemente a la carga de los datos en un dataset, como uno esperar√≠a te√≥ricamente.\n",
    "\n",
    "- Se puede ver que incluso la ejecuci√≥n usando BigQuery (que deber√≠a ocupar muy poca memoria, ya que el trabajo lo hacen los servidores de Google) usa sobre 100MB, lo que indica que las funciones de optimizaci√≥n de memor√≠a son muy eficientes, puesto que ocupan una memor√≠a parecida.\n",
    "\n",
    "- Se puede ver que los distintos enfoques entregan los mismos resultados, lo que hace probable que esten correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Posibles mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una posible mejora es preprocesar los datos para cargarlos m√°s r√°pidamente en los Dataframes de Pandas y Polars. Resulta interesante usar el formato parquet para guardar los Dataframes dada su eficiencia y velocidad. Puesto que la mayor parte del tiempo de ejecuci√≥n usando Pandas se gasta en la carga, resulta interesante esta opci√≥n para comparar en iguales condiciones con Polars.\n",
    "\n",
    "- Una mejora ser√≠a usar librer√≠as m√°s completas (como cProfle) para evaluar el tiempo de ejecuci√≥n, con el fin de descubrir posibles cuello de botella en las funciones. Ser√≠a una buena forma de confirmar la sospecha de los tiempo de carga en los Dataframe.\n",
    "\n",
    "- Otra posible mejora es agregar el tiempo de carga de los datos en el caso de BigQuery, ya que con Pandas y Polars es el factor que m√°s afecta.\n",
    "\n",
    "- Tambi√©n ser√≠a bueno agregar mayor documentaci√≥n sobre el setup de Google Cloud Platform, con cada paso explicado m√°s detalladamente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
